{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\ntrain = pd.read_csv(\"train.csv\")",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "train.head(5)",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cb774db0d1</td>\n      <td>I`d have responded, if I were going</td>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549e992a42</td>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>Sooo SAD</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>088c60f138</td>\n      <td>my boss is bullying me...</td>\n      <td>bullying me</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9642c003ef</td>\n      <td>what interview! leave me alone</td>\n      <td>leave me alone</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>358bd9e861</td>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>Sons of ****,</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "       textID                                               text  \\\n0  cb774db0d1                I`d have responded, if I were going   \n1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n2  088c60f138                          my boss is bullying me...   \n3  9642c003ef                     what interview! leave me alone   \n4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n\n                         selected_text sentiment  \n0  I`d have responded, if I were going   neutral  \n1                             Sooo SAD  negative  \n2                          bullying me  negative  \n3                       leave me alone  negative  \n4                        Sons of ****,  negative  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "## statistics \n### Explore number of sentiments"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\n\ntrain.sentiment.value_counts()",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "neutral     11118\npositive     8582\nnegative     7781\nName: sentiment, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### clean text, remove url link, stop words, stem words"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import re\nimport string\ndef clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "train[\"text\"] = train[\"text\"].apply(lambda x: clean_text(x))\ntrain['selected_text'] = train['selected_text'].apply(lambda x:clean_text(x))",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import nltk\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize \nnltk.download('stopwords')\nnltk.download('punkt')\n#word_tokenize accepts a string as an input, not a file. \nstop_words = set(stopwords.words('english')) \n\ndef remove_stopwords(words):\n    text = []\n    for word in word_tokenize(words):\n        if not word in stop_words:\n            text.append(word)\n    return ' '.join(text)\n\ntrain[\"text\"] = train[\"text\"].apply(lambda x: remove_stopwords(x))\ntrain['selected_text'] = train['selected_text'].apply(lambda x:remove_stopwords(x))",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[nltk_data] Downloading package stopwords to /home/nbuser/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /home/nbuser/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from nltk.stem import PorterStemmer \nfrom nltk.tokenize import word_tokenize \n   \nps = PorterStemmer() \n\ndef stem_word(words):\n    text = []\n    for word in word_tokenize(words):\n        text.append(ps.stem(word))\n    return \" \".join(text)\ntrain[\"text\"] = train[\"text\"].apply(lambda x: stem_word(x))\ntrain['selected_text'] = train['selected_text'].apply(lambda x:stem_word(x))",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from collections import Counter\ncnt = Counter()\nfor line in range(len(train)):\n    for word in word_tokenize(train.iloc[line, 1]):\n        cnt[word] += 1",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cnt.most_common(20)",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "[('im', 3023),\n ('day', 2368),\n ('go', 2363),\n ('get', 1908),\n ('good', 1569),\n ('work', 1483),\n ('love', 1456),\n ('like', 1454),\n ('got', 1238),\n ('dont', 1200),\n ('today', 1114),\n ('time', 1078),\n ('one', 1055),\n ('cant', 1020),\n ('happi', 993),\n ('want', 981),\n ('know', 967),\n ('miss', 961),\n ('thank', 961),\n ('lol', 950)]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The most common words in the dataset exprims some sentiments like love/like, good, don't, miss etc..."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Positive_sent = train[train['sentiment']=='positive']\nNegative_sent = train[train['sentiment']=='negative']\nNeutral_sent = train[train['sentiment']=='neutral']",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from collections import Counter\ncnt = Counter()\nfor line in range(len(Positive_sent)):\n    for word in word_tokenize(Positive_sent.iloc[line, 2]):\n        cnt[word] += 1\ncnt.most_common(10)",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "[('love', 910),\n ('good', 832),\n ('happi', 739),\n ('thank', 633),\n ('day', 471),\n ('great', 364),\n ('hope', 335),\n ('fun', 287),\n ('nice', 270),\n ('mother', 269)]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from collections import Counter\ncnt = Counter()\nfor line in range(len(Negative_sent)):\n    for word in word_tokenize(Negative_sent.iloc[line, 2]):\n        cnt[word] += 1\ncnt.most_common(10)",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "[('miss', 550),\n ('im', 452),\n ('sad', 352),\n ('sorri', 302),\n ('hate', 273),\n ('bad', 246),\n ('feel', 242),\n ('dont', 221),\n ('suck', 217),\n ('cant', 201)]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from collections import Counter\ncnt = Counter()\nfor line in range(len(Neutral_sent)):\n    for word in word_tokenize(Neutral_sent.iloc[line, 2]):\n        cnt[word] += 1\ncnt.most_common(10)",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "[('go', 1041),\n ('im', 1040),\n ('get', 806),\n ('work', 633),\n ('day', 622),\n ('got', 526),\n ('dont', 482),\n ('like', 470),\n ('time', 455),\n ('want', 441)]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "### Use spacy to create NER"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def get_train_datas(data):\n    train_datas = []\n    texts = data.text\n    selected_texts = data.selected_text\n    for selected_text, text in zip(selected_texts, texts):\n        start = text.find(selected_text)\n        end = start + len(selected_text)\n        train_datas.append((text, {\"entities\":[(start, end, \"selected_text\")]}))\n    return train_datas",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "positive_tweet = get_train_datas(Positive_sent)\nnegative_tweet = get_train_datas(Negative_sent)",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def load_model(pre_model = None, label = None):\n    if pre_model is not None:\n        nlp = spacy.load(pre_model)\n        print(\"Loaded model '%s'\" % pre_model)\n    else:\n        nlp = spacy.blank(\"en\")  # create blank Language class\n        print(\"Created blank 'en' model\")\n\n        if \"ner\" not in nlp.pipe_names:\n            ner = nlp.create_pipe(\"ner\")\n            nlp.add_pipe(ner)\n        else:\n            ner = nlp.get_pipe(\"ner\")\n\n        if label is not None:\n            ner.add_label(label)\n\n    return nlp",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def train_model(model, nlp, train_datas, n_iter = 30):\n    if model is None:\n        optimizer = nlp.begin_training()\n    else:\n        optimizer = nlp.resume_training()\n    pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n\n    with nlp.disable_pipes(*other_pipes):\n        sizes = compounding(1.0, 64.0, 1.001)\n        print(train_datas[0])\n        for itn in range(n_iter):\n            random.shuffle(train_datas)\n            batches = minibatch(train_datas, size=sizes)\n            losses = {}\n            for batch in batches:\n                texts, annotations = zip(*batch)\n                nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n            print(itn, \"Losses\", losses)\n\n    return nlp",
      "execution_count": 42,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\ndef test_model(ner_model, text):\n    doc = ner_model(text)\n    ent_array = []\n    for ent in doc.ents:\n        start = text.find(ent.text)\n        end = start + len(ent.text)\n        new_int = [start, end, ent.label_]\n        \n        if new_int not in ent_array:\n            ent_array.append([start, end, ent.label_])\n        \n    return text[ent_array[0][0]:ent_array[0][1]] if len(ent_array) > 0 else text\n\n\ndef save_model(ner_model, output_dir = None, new_model_name = None):\n    if output_dir is not None:\n        output_dir = Path(output_dir)\n        if not output_dir.exists():\n            output_dir.mkdir()\n        ner_model.meta[\"name\"] = new_model_name\n        ner_model.to_disk(output_dir)\n        print(\"Saved model to\", output_dir)",
      "execution_count": 43,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def get_model(sentiment, train_datas, more_iters = 30):\n    if sentiment == 'positive':\n        positive_model_path = \"./models/positive_ner/\"\n        positive_datas = train_datas\n        if not os.path.exists(positive_model_path):\n            nlp = load_model(label = 'selected_text')\n            ner_model_positive = train_model(None, nlp, positive_datas, n_iter=50)\n            save_model(ner_model_positive, output_dir = \"./models/positive_ner/\", new_model_name = \"posi_model\")\n        else:\n            ner_model_positive = load_model(positive_model_path)\n#             ner_model_positive = spacy.load(\"/kaggle/working/models\")\n            if more_iters > 0:\n                ner_model_positive = train_model(positive_model_path, ner_model_positive, positive_datas, more_iters)\n                save_model(ner_model_positive, output_dir = \"./\", new_model_name = \"posi_model\")\n        return ner_model_positive\n    else:\n        negative_model_path = \"./\"\n        negative_datas = train_datas\n        if not os.path.exists(negative_model_path):\n            nlp = load_model(label = 'selected_text')\n            ner_model_negative = train_model(None, nlp, negative_datas, n_iter=50)\n            save_model(ner_model_negative, output_dir = \"./\", new_model_name = \"nega_model\")\n        else:\n            ner_model_negative = load_model(negative_model_path)\n#             ner_model_negative = spacy.load(\"/kaggle/working/models_nega\")\n            if more_iters > 0:\n                ner_model_negative = train_model(negative_model_path, ner_model_negative, negative_datas, more_iters)\n                save_model(ner_model_negative, output_dir = \"./\", new_model_name = \"nega_model\")\n        return ner_model_negative",
      "execution_count": 44,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "from __future__ import unicode_literals, print_function\n!pip install spacy\nimport spacy\nimport plac\nimport random\nfrom pathlib import Path\nimport spacy\nfrom spacy.util import minibatch, compounding\nner_model_positive = get_model('positive', positive_tweet, more_iters=50)",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Requirement already satisfied: spacy in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (2.2.4)\nRequirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from spacy) (1.0.2)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from spacy) (4.46.0)\nRequirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from spacy) (1.0.0)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from spacy) (1.0.2)\nRequirement already satisfied: blis<0.5.0,>=0.4.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from spacy) (0.4.1)\nRequirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from spacy) (0.6.0)\nRequirement already satisfied: setuptools in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from spacy) (41.6.0)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from spacy) (3.0.2)\nRequirement already satisfied: numpy>=1.15.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from spacy) (1.16.2)\nRequirement already satisfied: plac<1.2.0,>=0.9.6 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from spacy) (1.1.3)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from spacy) (2.22.0)\nRequirement already satisfied: thinc==7.4.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from spacy) (7.4.0)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from spacy) (2.0.3)\nRequirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.0)\nRequirement already satisfied: certifi>=2017.4.17 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2018.10.15)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.23)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\nRequirement already satisfied: idna<2.9,>=2.5 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.7)\nRequirement already satisfied: zipp>=0.5 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\nCreated blank 'en' model\n(' feedings for the baby are fun when he is all smiles and coos', {'entities': [(27, 30, 'selected_text')]})\n",
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\npython -m spacy debug-data --help",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-f1f660b993f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompounding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mner_model_positive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'positive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_tweet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmore_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-44-0315147d1ec3>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(sentiment, train_datas, more_iters)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'selected_text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mner_model_positive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_datas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mner_model_positive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./models/positive_ner/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_model_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"posi_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-f2815d98d3d2>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, nlp, train_datas, n_iter)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Losses\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, docs, golds, drop, sgd, losses, component_cfg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                 \u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.update\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser._init_gold_batch\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mtransition_system.pyx\u001b[0m in \u001b[0;36mspacy.syntax.transition_system.TransitionSystem.get_oracle_sequence\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mtransition_system.pyx\u001b[0m in \u001b[0;36mspacy.syntax.transition_system.TransitionSystem.set_costs\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: [E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\npython -m spacy debug-data --help"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Positive_sent",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 46,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>6e0c6d75b1</td>\n      <td>feedings for the baby are fun when he is all ...</td>\n      <td>fun</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>fc2cbefa9d</td>\n      <td>journey wow u just became cooler  hehe is tha...</td>\n      <td>wow u just became cooler</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>16fab9f95b</td>\n      <td>i really really like the song love story by ta...</td>\n      <td>like</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>e48b0b8a23</td>\n      <td>playing ghost online is really interesting the...</td>\n      <td>interesting</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>e00c6ef376</td>\n      <td>the free fillin app on my ipod is fun im addicted</td>\n      <td>the free fillin app on my ipod is fun im addicted</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>6ce4a4954b</td>\n      <td>juss came backk from berkeleyy  omg its madd f...</td>\n      <td>fun</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>d33f811375</td>\n      <td>im going home now have you seen my new twitter...</td>\n      <td>quiteheavenly</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>7d8c4c11e4</td>\n      <td>i hope unni will make the audition  fighting d...</td>\n      <td>hope</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>2dc51711bc</td>\n      <td>thats very funny  cute kids</td>\n      <td>funny</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>2863f435bd</td>\n      <td>a little happy for the wine jeje ok itsm my fr...</td>\n      <td>a little happy fo</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>fab6b7d16c</td>\n      <td>im an avid fan of  magazine and i love your ma...</td>\n      <td>avid fan of</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>c77717b103</td>\n      <td>i love to but im only available from   and wh...</td>\n      <td>i love to</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>d8ba2a99a9</td>\n      <td>romance zero is funny</td>\n      <td>romance zero is funny</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>90a2cdb657</td>\n      <td>what better way to spoil mum than to let her k...</td>\n      <td>favorite</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>95e12b1cb1</td>\n      <td>hes awesome have you worked with him before ...</td>\n      <td>s awesome</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>fa2654e730</td>\n      <td>chilliin</td>\n      <td>chilliin</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>a4e00d4d26</td>\n      <td>a celticslakers rematch sounds better dont yo...</td>\n      <td>better</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>bbbc46889b</td>\n      <td>thank yyyyyyyyyoooooooooouuuuu</td>\n      <td>thank yyyyyyyyyoooooooooouuuuu</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>58d382e07a</td>\n      <td>lucky kidi so wanna see loserville  pity im i...</td>\n      <td>lucky</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>3d2fcd78c8</td>\n      <td>happy star wars day everyone and enjoy the hol...</td>\n      <td>happy star wars day everyone and enjoy the hol...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>9339ee8e0b</td>\n      <td>well what im working on isnt quite ready to p...</td>\n      <td>cool</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>a76f9cf8ce</td>\n      <td>sweeeeet  san fran is awesome  love it there</td>\n      <td>love it there</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>4c41a35a2a</td>\n      <td>happy mothers day to all you mums out there</td>\n      <td>happy mothers day to all you mums out there</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>92e1b6846e</td>\n      <td>we saw that in none   the baddies the best</td>\n      <td>best</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>2207d982bc</td>\n      <td>and im on the beach pretty</td>\n      <td>pretty</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>6b018d3d2d</td>\n      <td>awesome  im down in ocean beach if you know w...</td>\n      <td>awesome</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>40649553ef</td>\n      <td>haha i do not know how to work blip apart fro...</td>\n      <td>thanks</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>561b44a42f</td>\n      <td>have a safe trip joshy pooyoull knock them de...</td>\n      <td>safe</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>109</th>\n      <td>a05aea73d7</td>\n      <td>woof i wish i was allowed to go</td>\n      <td>i wish i was allowed to go</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>112</th>\n      <td>d421fbd332</td>\n      <td>thank you afrin nasal spray also i got a giant...</td>\n      <td>thank you</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27397</th>\n      <td>734ab2cf0d</td>\n      <td>bottle of reisling this time my favorite</td>\n      <td>favorite</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27398</th>\n      <td>00fe74d2e4</td>\n      <td>haha thats way cool good morning</td>\n      <td>haha thats way cool</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27400</th>\n      <td>3c5450835e</td>\n      <td>i still have them yay gonna eat some now</td>\n      <td>yay</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27401</th>\n      <td>261e064dd4</td>\n      <td>oh silence verona  i am wanting to go   jaja ...</td>\n      <td>ja enjoyyitverymu</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27407</th>\n      <td>04db7e701e</td>\n      <td>really really wants to go and see coraline</td>\n      <td>really really wants to go and see coraline</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27412</th>\n      <td>878acf5421</td>\n      <td>i wish you were in my class last year</td>\n      <td>i wish you were in my class last year</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27413</th>\n      <td>4887a44500</td>\n      <td>so trueand so poetic beautiful</td>\n      <td>beautiful</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27415</th>\n      <td>09518a24aa</td>\n      <td>hey pinky i ordered some stuff from that site...</td>\n      <td>so pretty  thanks</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27417</th>\n      <td>2151413f96</td>\n      <td>ish okay my loveee</td>\n      <td>ish okay my loveee</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27424</th>\n      <td>772db3be6a</td>\n      <td>stoppped following ama i really need a clean b...</td>\n      <td>super nice</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27425</th>\n      <td>ef389b4d71</td>\n      <td>happy mothers day to all mums in america</td>\n      <td>happy</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27428</th>\n      <td>e02ea8a95c</td>\n      <td>i hate my presentation  hahah whatever im glad...</td>\n      <td>im glad</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27433</th>\n      <td>705ca50b20</td>\n      <td>at least they  kids havnt gotten to big to sti...</td>\n      <td>awww they are so sweet i am so lucky to have m...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27434</th>\n      <td>0a43c46417</td>\n      <td>really good night</td>\n      <td>really good night</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27435</th>\n      <td>744ae79733</td>\n      <td>back from cycling  miles on virtually traffic ...</td>\n      <td>great start</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27443</th>\n      <td>213c5cbfb4</td>\n      <td>yes i love him i have seen the eps so many ti...</td>\n      <td>i love him</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27446</th>\n      <td>9b0d10c5b9</td>\n      <td>i am glad cos u wouldnt lose me as a fan anyw...</td>\n      <td>i am glad</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27451</th>\n      <td>16947b5a23</td>\n      <td>happy all my studying and all nighters payed off</td>\n      <td>happy all</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27454</th>\n      <td>465b9edc97</td>\n      <td>mayer id like to see a picture of you carl and...</td>\n      <td>youre proud of and you love eachother</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27455</th>\n      <td>768e382964</td>\n      <td>simple greetings from unexpected people can ac...</td>\n      <td>simple greetings from unexpected people can ac...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27458</th>\n      <td>ea8072c6a6</td>\n      <td>i really wish someone would make a groupchat t...</td>\n      <td>really wish</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27459</th>\n      <td>13e1519ce3</td>\n      <td>good as cya in melbourne</td>\n      <td>good</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27461</th>\n      <td>c37b979e7e</td>\n      <td>again thanks to my dear neighboor who also ga...</td>\n      <td>thanks</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27462</th>\n      <td>3f9912ec7a</td>\n      <td>just back from bingo wfamily  i won over  fun ...</td>\n      <td>fun</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27465</th>\n      <td>c14a543497</td>\n      <td>sure ill try n keep that up p you enjoy study...</td>\n      <td>enjoy</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27467</th>\n      <td>432e6de6c9</td>\n      <td>morning twitfriends welcome to my new followers</td>\n      <td>welcome</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27474</th>\n      <td>8f14bb2715</td>\n      <td>so i get up early and i feel good about the da...</td>\n      <td>i feel good ab</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27475</th>\n      <td>b78ec00df5</td>\n      <td>enjoy ur night</td>\n      <td>enjoy</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27478</th>\n      <td>f67aae2310</td>\n      <td>yay good for both of you enjoy the break  you...</td>\n      <td>yay good for both of you</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27479</th>\n      <td>ed167662a5</td>\n      <td>but it was worth it</td>\n      <td>but it was worth it</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n<p>8582 rows Ã— 4 columns</p>\n</div>",
            "text/plain": "           textID                                               text  \\\n6      6e0c6d75b1   feedings for the baby are fun when he is all ...   \n9      fc2cbefa9d   journey wow u just became cooler  hehe is tha...   \n11     16fab9f95b  i really really like the song love story by ta...   \n21     e48b0b8a23  playing ghost online is really interesting the...   \n25     e00c6ef376  the free fillin app on my ipod is fun im addicted   \n28     6ce4a4954b  juss came backk from berkeleyy  omg its madd f...   \n30     d33f811375  im going home now have you seen my new twitter...   \n31     7d8c4c11e4  i hope unni will make the audition  fighting d...   \n33     2dc51711bc                        thats very funny  cute kids   \n39     2863f435bd  a little happy for the wine jeje ok itsm my fr...   \n41     fab6b7d16c  im an avid fan of  magazine and i love your ma...   \n44     c77717b103   i love to but im only available from   and wh...   \n54     d8ba2a99a9                              romance zero is funny   \n63     90a2cdb657  what better way to spoil mum than to let her k...   \n66     95e12b1cb1    hes awesome have you worked with him before ...   \n68     fa2654e730                                           chilliin   \n71     a4e00d4d26   a celticslakers rematch sounds better dont yo...   \n80     bbbc46889b                     thank yyyyyyyyyoooooooooouuuuu   \n81     58d382e07a   lucky kidi so wanna see loserville  pity im i...   \n85     3d2fcd78c8  happy star wars day everyone and enjoy the hol...   \n89     9339ee8e0b   well what im working on isnt quite ready to p...   \n90     a76f9cf8ce       sweeeeet  san fran is awesome  love it there   \n95     4c41a35a2a        happy mothers day to all you mums out there   \n99     92e1b6846e         we saw that in none   the baddies the best   \n100    2207d982bc                         and im on the beach pretty   \n104    6b018d3d2d   awesome  im down in ocean beach if you know w...   \n107    40649553ef   haha i do not know how to work blip apart fro...   \n108    561b44a42f   have a safe trip joshy pooyoull knock them de...   \n109    a05aea73d7                    woof i wish i was allowed to go   \n112    d421fbd332  thank you afrin nasal spray also i got a giant...   \n...           ...                                                ...   \n27397  734ab2cf0d           bottle of reisling this time my favorite   \n27398  00fe74d2e4                   haha thats way cool good morning   \n27400  3c5450835e           i still have them yay gonna eat some now   \n27401  261e064dd4   oh silence verona  i am wanting to go   jaja ...   \n27407  04db7e701e         really really wants to go and see coraline   \n27412  878acf5421              i wish you were in my class last year   \n27413  4887a44500                     so trueand so poetic beautiful   \n27415  09518a24aa   hey pinky i ordered some stuff from that site...   \n27417  2151413f96                                 ish okay my loveee   \n27424  772db3be6a  stoppped following ama i really need a clean b...   \n27425  ef389b4d71           happy mothers day to all mums in america   \n27428  e02ea8a95c  i hate my presentation  hahah whatever im glad...   \n27433  705ca50b20  at least they  kids havnt gotten to big to sti...   \n27434  0a43c46417                                  really good night   \n27435  744ae79733  back from cycling  miles on virtually traffic ...   \n27443  213c5cbfb4   yes i love him i have seen the eps so many ti...   \n27446  9b0d10c5b9   i am glad cos u wouldnt lose me as a fan anyw...   \n27451  16947b5a23   happy all my studying and all nighters payed off   \n27454  465b9edc97  mayer id like to see a picture of you carl and...   \n27455  768e382964  simple greetings from unexpected people can ac...   \n27458  ea8072c6a6  i really wish someone would make a groupchat t...   \n27459  13e1519ce3                           good as cya in melbourne   \n27461  c37b979e7e   again thanks to my dear neighboor who also ga...   \n27462  3f9912ec7a  just back from bingo wfamily  i won over  fun ...   \n27465  c14a543497   sure ill try n keep that up p you enjoy study...   \n27467  432e6de6c9    morning twitfriends welcome to my new followers   \n27474  8f14bb2715  so i get up early and i feel good about the da...   \n27475  b78ec00df5                                     enjoy ur night   \n27478  f67aae2310   yay good for both of you enjoy the break  you...   \n27479  ed167662a5                              but it was worth it     \n\n                                           selected_text sentiment  \n6                                                    fun  positive  \n9                               wow u just became cooler  positive  \n11                                                  like  positive  \n21                                           interesting  positive  \n25     the free fillin app on my ipod is fun im addicted  positive  \n28                                                   fun  positive  \n30                                         quiteheavenly  positive  \n31                                                  hope  positive  \n33                                                 funny  positive  \n39                                     a little happy fo  positive  \n41                                           avid fan of  positive  \n44                                             i love to  positive  \n54                                 romance zero is funny  positive  \n63                                              favorite  positive  \n66                                             s awesome  positive  \n68                                              chilliin  positive  \n71                                                better  positive  \n80                        thank yyyyyyyyyoooooooooouuuuu  positive  \n81                                                 lucky  positive  \n85     happy star wars day everyone and enjoy the hol...  positive  \n89                                                  cool  positive  \n90                                         love it there  positive  \n95           happy mothers day to all you mums out there  positive  \n99                                                  best  positive  \n100                                               pretty  positive  \n104                                              awesome  positive  \n107                                               thanks  positive  \n108                                                 safe  positive  \n109                           i wish i was allowed to go  positive  \n112                                            thank you  positive  \n...                                                  ...       ...  \n27397                                           favorite  positive  \n27398                                haha thats way cool  positive  \n27400                                                yay  positive  \n27401                                  ja enjoyyitverymu  positive  \n27407         really really wants to go and see coraline  positive  \n27412              i wish you were in my class last year  positive  \n27413                                          beautiful  positive  \n27415                                  so pretty  thanks  positive  \n27417                                 ish okay my loveee  positive  \n27424                                         super nice  positive  \n27425                                              happy  positive  \n27428                                            im glad  positive  \n27433  awww they are so sweet i am so lucky to have m...  positive  \n27434                                  really good night  positive  \n27435                                        great start  positive  \n27443                                         i love him  positive  \n27446                                          i am glad  positive  \n27451                                          happy all  positive  \n27454              youre proud of and you love eachother  positive  \n27455  simple greetings from unexpected people can ac...  positive  \n27458                                        really wish  positive  \n27459                                               good  positive  \n27461                                             thanks  positive  \n27462                                                fun  positive  \n27465                                              enjoy  positive  \n27467                                            welcome  positive  \n27474                                     i feel good ab  positive  \n27475                                              enjoy  positive  \n27478                           yay good for both of you  positive  \n27479                              but it was worth it    positive  \n\n[8582 rows x 4 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}