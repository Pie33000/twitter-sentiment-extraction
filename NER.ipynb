{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Tweet sentiment extraction\n#### This noteboook explore some methods to extract sentiment from a tweet\n<ul>\n    <li>Space Name Entity Recognition</li>\n    <li>Roberta inference model with Pytorch</li>\n</ul>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\ntrain = pd.read_csv(\"./Data/train.csv\")",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "train.head(5)",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cb774db0d1</td>\n      <td>I`d have responded, if I were going</td>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549e992a42</td>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>Sooo SAD</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>088c60f138</td>\n      <td>my boss is bullying me...</td>\n      <td>bullying me</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9642c003ef</td>\n      <td>what interview! leave me alone</td>\n      <td>leave me alone</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>358bd9e861</td>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>Sons of ****,</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "       textID                                               text  \\\n0  cb774db0d1                I`d have responded, if I were going   \n1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n2  088c60f138                          my boss is bullying me...   \n3  9642c003ef                     what interview! leave me alone   \n4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n\n                         selected_text sentiment  \n0  I`d have responded, if I were going   neutral  \n1                             Sooo SAD  negative  \n2                          bullying me  negative  \n3                       leave me alone  negative  \n4                        Sons of ****,  negative  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## statistics \n### Explore number of sentiments"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\n\ntrain.sentiment.value_counts()",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "neutral     11118\npositive     8582\nnegative     7781\nName: sentiment, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### clean text, remove url link, stop words, stem words"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import re\nimport string\ndef clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "train[\"text\"] = train[\"text\"].apply(lambda x: clean_text(x))\ntrain['selected_text'] = train['selected_text'].apply(lambda x:clean_text(x))",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from nltk.stem import PorterStemmer \nfrom nltk.tokenize import word_tokenize \n   \nps = PorterStemmer() \n\ndef stem_word(words):\n    text = []\n    for word in word_tokenize(words):\n        text.append(ps.stem(word))\n    return \" \".join(text)\ntrain[\"text\"] = train[\"text\"].apply(lambda x: stem_word(x))\ntrain['selected_text'] = train['selected_text'].apply(lambda x:stem_word(x))",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from collections import Counter\ncnt = Counter()\nfor line in range(len(train)):\n    for word in word_tokenize(train.iloc[line, 1]):\n        cnt[word] += 1",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "cnt.most_common(20)",
      "execution_count": 14,
      "outputs": [
        {
          "data": {
            "text/plain": "[('im', 3023),\n ('day', 2368),\n ('go', 2363),\n ('get', 1908),\n ('good', 1569),\n ('work', 1483),\n ('love', 1456),\n ('like', 1454),\n ('got', 1238),\n ('dont', 1200),\n ('today', 1114),\n ('time', 1078),\n ('one', 1055),\n ('cant', 1020),\n ('happi', 993),\n ('want', 981),\n ('know', 967),\n ('miss', 961),\n ('thank', 961),\n ('lol', 950)]"
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The most common words in the dataset exprims some sentiments like love/like, good, don't, miss etc..."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from collections import Counter\ncnt = Counter()\nfor line in range(len(Positive_sent)):\n    for word in word_tokenize(Positive_sent.iloc[line, 2]):\n        cnt[word] += 1\ncnt.most_common(10)",
      "execution_count": 16,
      "outputs": [
        {
          "data": {
            "text/plain": "[('love', 910),\n ('good', 832),\n ('happi', 739),\n ('thank', 633),\n ('day', 471),\n ('great', 364),\n ('hope', 335),\n ('fun', 287),\n ('nice', 270),\n ('mother', 269)]"
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from collections import Counter\ncnt = Counter()\nfor line in range(len(Negative_sent)):\n    for word in word_tokenize(Negative_sent.iloc[line, 2]):\n        cnt[word] += 1\ncnt.most_common(10)",
      "execution_count": 17,
      "outputs": [
        {
          "data": {
            "text/plain": "[('miss', 550),\n ('im', 452),\n ('sad', 352),\n ('sorri', 302),\n ('hate', 273),\n ('bad', 246),\n ('feel', 242),\n ('dont', 221),\n ('suck', 217),\n ('cant', 201)]"
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from collections import Counter\ncnt = Counter()\nfor line in range(len(Neutral_sent)):\n    for word in word_tokenize(Neutral_sent.iloc[line, 2]):\n        cnt[word] += 1\ncnt.most_common(10)",
      "execution_count": 18,
      "outputs": [
        {
          "data": {
            "text/plain": "[('go', 1041),\n ('im', 1040),\n ('get', 806),\n ('work', 633),\n ('day', 622),\n ('got', 526),\n ('dont', 482),\n ('like', 470),\n ('time', 455),\n ('want', 441)]"
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Train Spacy Name Entity Recognition (NER)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def get_train_datas(data):\n    train_datas = []\n    texts = data.text\n    selected_texts = data.selected_text\n    for selected_text, text in zip(selected_texts, texts):\n        start = text.find(selected_text)\n        end = start + len(selected_text)\n        train_datas.append((text, {\"entities\":[(start, end, \"selected_text\")]}))\n    return train_datas",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def load_model(pre_model = None, label = None):\n    if pre_model is not None:\n        nlp = spacy.load(pre_model)\n        print(\"Loaded model '%s'\" % pre_model)\n    else:\n        nlp = spacy.blank(\"en\")  # create blank Language class\n        print(\"Created blank 'en' model\")\n\n        if \"ner\" not in nlp.pipe_names:\n            ner = nlp.create_pipe(\"ner\")\n            nlp.add_pipe(ner)\n        else:\n            ner = nlp.get_pipe(\"ner\")\n\n        if label is not None:\n            ner.add_label(label)\n\n    return nlp",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def train_model(model, nlp, train_datas, n_iter = 30):\n    if model is None:\n        optimizer = nlp.begin_training()\n    else:\n        optimizer = nlp.resume_training()\n    pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n\n    with nlp.disable_pipes(*other_pipes):\n        sizes = compounding(1.0, 64.0, 1.001)\n        print(train_datas[0])\n        for itn in range(n_iter):\n            random.shuffle(train_datas)\n            batches = minibatch(train_datas, size=sizes)\n            losses = {}\n            for batch in batches:\n                texts, annotations = zip(*batch)\n                nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n            print(itn, \"Losses\", losses)\n\n    return nlp",
      "execution_count": 29,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\ndef test_model(ner_model, text):\n    doc = ner_model(text)\n    ent_array = []\n    for ent in doc.ents:\n        start = text.find(ent.text)\n        end = start + len(ent.text)\n        new_int = [start, end, ent.label_]\n        \n        if new_int not in ent_array:\n            ent_array.append([start, end, ent.label_])\n        \n    return text[ent_array[0][0]:ent_array[0][1]] if len(ent_array) > 0 else text\n\n\ndef save_model(ner_model, output_dir = None, new_model_name = None):\n    if output_dir is not None:\n        output_dir = Path(output_dir)\n        if not output_dir.exists():\n            output_dir.mkdir()\n        ner_model.meta[\"name\"] = new_model_name\n        ner_model.to_disk(output_dir)\n        print(\"Saved model to\", output_dir)",
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def get_model(sentiment, train_datas, more_iters = 30):\n    if sentiment == 'positive':\n        positive_model_path = \"./models/positive_ner/\"\n        positive_datas = train_datas\n        if not os.path.exists(positive_model_path):\n            nlp = load_model(label = 'selected_text')\n            ner_model_positive = train_model(None, nlp, positive_datas, n_iter=50)\n            save_model(ner_model_positive, output_dir = \"./models/positive_ner/\", new_model_name = \"posi_model\")\n        else:\n            ner_model_positive = load_model(positive_model_path)\n#             ner_model_positive = spacy.load(\"/kaggle/working/models\")\n            if more_iters > 0:\n                ner_model_positive = train_model(positive_model_path, ner_model_positive, positive_datas, more_iters)\n                save_model(ner_model_positive, output_dir = \"./models/positive_ner/\", new_model_name = \"posi_model\")\n        return ner_model_positive\n    else:\n        negative_model_path = \"./models/negative_ner/\"\n        negative_datas = train_datas\n        if not os.path.exists(negative_model_path):\n            nlp = load_model(label = 'selected_text')\n            ner_model_negative = train_model(None, nlp, negative_datas, n_iter=50)\n            save_model(ner_model_negative, output_dir = \"./models/negative_ner/\", new_model_name = \"nega_model\")\n        else:\n            ner_model_negative = load_model(negative_model_path)\n#             ner_model_negative = spacy.load(\"/kaggle/working/models_nega\")\n            if more_iters > 0:\n                ner_model_negative = train_model(negative_model_path, ner_model_negative, negative_datas, more_iters)\n                save_model(ner_model_negative, output_dir = \"./models/negative_ner/\", new_model_name = \"nega_model\")\n        return ner_model_negative",
      "execution_count": 26,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from tensorflow.keras.preprocessing.text import text_to_word_sequence\nPositive_sent = train[train['sentiment']=='positive']\nNegative_sent = train[train['sentiment']=='negative']\nNeutral_sent = train[train['sentiment']=='neutral']\n\nPositive_sent = Positive_sent.reindex(axis=1)\nPositive_sent[\"text\"] = Positive_sent[\"text\"].apply(lambda x: x.strip())\nNegative_sent = Negative_sent.reindex(axis=1)\nNegative_sent[\"text\"] = Negative_sent[\"text\"].apply(lambda x: x.strip())\n\nPositive_sent[\"text\"] = Positive_sent[\"text\"].apply(lambda text: ' '.join(text_to_word_sequence(\n    text, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' '\n)))\nNegative_sent[\"text\"] = Negative_sent[\"text\"].apply(lambda text: ' '.join(text_to_word_sequence(\n    text, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' '\n)))\n\npositive_tweet = get_train_datas(Positive_sent)\nnegative_tweet = get_train_datas(Negative_sent)\n\npositive_tweet_train = []\nfor i in range(len(positive_tweet)):\n    if positive_tweet[i][0] != \"\":\n        positive_tweet_train.append(positive_tweet[i])\n        \nnegative_tweet_train = []\nfor i in range(len(negative_tweet)):\n    if negative_tweet[i][0] != \"\":\n        negative_tweet_train.append(positive_tweet[i])",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from __future__ import unicode_literals, print_function\n!pip install spacy\nimport spacy\nimport plac\nimport random\nfrom pathlib import Path\nimport spacy\nfrom spacy.util import minibatch, compounding",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Collecting spacy\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/2e/ac00f5c9d01e66cc6ab75eb2a460c9b0dc21ad99a12f810c86a58309e63c/spacy-2.2.4-cp36-cp36m-manylinux1_x86_64.whl (10.6MB)\n\u001b[K     |████████████████████████████████| 10.6MB 22kB/s  eta 0:00:01    |█████▌                          | 1.8MB 2.8MB/s eta 0:00:04     |██████████▎                     | 3.4MB 2.8MB/s eta 0:00:03███████▌                   | 4.1MB 1.3MB/s eta 0:00:06     |███████████████████▎            | 6.4MB 2.3MB/s eta 0:00:02\n\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from spacy) (2.22.0)\nCollecting srsly<1.1.0,>=1.0.2\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/9a/70bd934dd4d25545c9aa6c8cd4edbac2a33ba9c915439a9209b69f0ec0ad/srsly-1.0.2-cp36-cp36m-manylinux1_x86_64.whl (185kB)\n\u001b[K     |████████████████████████████████| 194kB 8.1MB/s eta 0:00:01\n\u001b[?25hCollecting plac<1.2.0,>=0.9.6\n  Downloading https://files.pythonhosted.org/packages/86/85/40b8f66c2dd8f4fd9f09d59b22720cffecf1331e788b8a0cab5bafb353d1/plac-1.1.3-py2.py3-none-any.whl\nCollecting cymem<2.1.0,>=2.0.2\n  Downloading https://files.pythonhosted.org/packages/e7/b5/3e1714ebda8fd7c5859f9b216e381adc0a38b962f071568fd00d67e1b1ca/cymem-2.0.3-cp36-cp36m-manylinux1_x86_64.whl\nCollecting thinc==7.4.0\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/ed/8e4559f1090fb05c0fa982a8a2caaa315967e7b460652be479d13fd1c813/thinc-7.4.0-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n\u001b[K     |████████████████████████████████| 2.2MB 122kB/s  eta 0:00:01\n\u001b[?25hCollecting blis<0.5.0,>=0.4.0\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/19/f95c75562d18eb27219df3a3590b911e78d131b68466ad79fdf5847eaac4/blis-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n\u001b[K     |████████████████████████████████| 3.7MB 55kB/s  eta 0:00:01\n\u001b[?25hCollecting wasabi<1.1.0,>=0.4.0\n  Downloading https://files.pythonhosted.org/packages/21/e1/e4e7b754e6be3a79c400eb766fb34924a6d278c43bb828f94233e0124a21/wasabi-0.6.0-py3-none-any.whl\nCollecting murmurhash<1.1.0,>=0.28.0\n  Downloading https://files.pythonhosted.org/packages/a6/e6/63f160a4fdf0e875d16b28f972083606d8d54f56cd30cb8929f9a1ee700e/murmurhash-1.0.2-cp36-cp36m-manylinux1_x86_64.whl\nRequirement already satisfied: setuptools in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from spacy) (41.6.0)\nCollecting preshed<3.1.0,>=3.0.2\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/6b/e07fad36913879757c90ba03d6fb7f406f7279e11dcefc105ee562de63ea/preshed-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (119kB)\n\u001b[K     |████████████████████████████████| 122kB 5.8MB/s eta 0:00:01\n\u001b[?25hCollecting tqdm<5.0.0,>=4.38.0\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/40/058b12e8ba10e35f89c9b1fdfc2d4c7f8c05947df2d5eb3c7b258019fda0/tqdm-4.46.0-py2.py3-none-any.whl (63kB)\n\u001b[K     |████████████████████████████████| 71kB 867kB/s eta 0:00:01\n\u001b[?25hCollecting catalogue<1.1.0,>=0.0.7\n  Downloading https://files.pythonhosted.org/packages/6c/f9/9a5658e2f56932e41eb264941f9a2cb7f3ce41a80cb36b2af6ab78e2f8af/catalogue-1.0.0-py2.py3-none-any.whl\nRequirement already satisfied: numpy>=1.15.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from spacy) (1.16.2)\nRequirement already satisfied: idna<2.9,>=2.5 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.7)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.23)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2018.10.15)\nCollecting importlib-metadata>=0.20; python_version < \"3.8\"\n  Downloading https://files.pythonhosted.org/packages/ad/e4/891bfcaf868ccabc619942f27940c77a8a4b45fd8367098955bb7e152fb1/importlib_metadata-1.6.0-py2.py3-none-any.whl\nCollecting zipp>=0.5\n  Downloading https://files.pythonhosted.org/packages/b2/34/bfcb43cc0ba81f527bc4f40ef41ba2ff4080e047acb0586b56b3d017ace4/zipp-3.1.0-py3-none-any.whl\nInstalling collected packages: srsly, plac, cymem, murmurhash, preshed, blis, wasabi, tqdm, zipp, importlib-metadata, catalogue, thinc, spacy\n  Found existing installation: tqdm 4.26.0\n    Uninstalling tqdm-4.26.0:\n      Successfully uninstalled tqdm-4.26.0\nSuccessfully installed blis-0.4.1 catalogue-1.0.0 cymem-2.0.3 importlib-metadata-1.6.0 murmurhash-1.0.2 plac-1.1.3 preshed-3.0.2 spacy-2.2.4 srsly-1.0.2 thinc-7.4.0 tqdm-4.46.0 wasabi-0.6.0 zipp-3.1.0\n\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "ner_model_positive = get_model('positive', positive_tweet_train, more_iters=100)",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Created blank 'en' model\n('happy mothers day to all beautiful mother may your love shines the world thank you mum', {'entities': [(0, 5, 'selected_text')]})\n0 Losses {'ner': 19844.369808229545}\n1 Losses {'ner': 19451.511896747164}\n2 Losses {'ner': 18303.655233740807}\n3 Losses {'ner': 17001.421297371387}\n4 Losses {'ner': 16384.183547489345}\n5 Losses {'ner': 15690.280764579773}\n6 Losses {'ner': 14684.084883540869}\n7 Losses {'ner': 14334.895932555199}\n8 Losses {'ner': 14110.978977087885}\n9 Losses {'ner': 13620.871316948906}\n10 Losses {'ner': 13251.155605793}\n11 Losses {'ner': 13107.195569038391}\n12 Losses {'ner': 12700.933847650595}\n13 Losses {'ner': 12408.254685401917}\n14 Losses {'ner': 12440.346844702959}\n15 Losses {'ner': 11924.934330686927}\n16 Losses {'ner': 11845.36424190551}\n17 Losses {'ner': 11593.078968308866}\n18 Losses {'ner': 11534.154551910433}\n19 Losses {'ner': 11579.725727168552}\n20 Losses {'ner': 11105.73508259654}\n21 Losses {'ner': 11059.292191986926}\n22 Losses {'ner': 10778.444511771202}\n23 Losses {'ner': 10588.87126083672}\n24 Losses {'ner': 10280.645943077594}\n25 Losses {'ner': 10465.078636057675}\n26 Losses {'ner': 10559.380920648575}\n27 Losses {'ner': 10185.15268583363}\n28 Losses {'ner': 10401.70285320282}\n29 Losses {'ner': 10156.396421206999}\n30 Losses {'ner': 9775.565871749073}\n31 Losses {'ner': 9704.953435659409}\n32 Losses {'ner': 10003.730420351028}\n33 Losses {'ner': 9745.008644200861}\n34 Losses {'ner': 9279.105643696035}\n35 Losses {'ner': 9237.444144316018}\n36 Losses {'ner': 9284.668305106461}\n37 Losses {'ner': 9282.698695540428}\n38 Losses {'ner': 9145.06842747517}\n39 Losses {'ner': 8888.051777600209}\n40 Losses {'ner': 8986.999446298694}\n41 Losses {'ner': 9171.290707335807}\n42 Losses {'ner': 8906.689765155315}\n43 Losses {'ner': 8770.725045242405}\n44 Losses {'ner': 8664.891371306847}\n45 Losses {'ner': 8370.421923726797}\n46 Losses {'ner': 8422.010416481644}\n47 Losses {'ner': 8385.302565446356}\n48 Losses {'ner': 8372.333626935259}\n49 Losses {'ner': 8446.96375861566}\nSaved model to models/positive_ner\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "ner_model_negative = get_model('negative', negative_tweet_tr, more_iters=50)",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Created blank 'en' model\n('happpppy mothers day', {'entities': [(0, 20, 'selected_text')]})\n0 Losses {'ner': 17817.433363507796}\n1 Losses {'ner': 17753.405313515163}\n2 Losses {'ner': 16018.647884458303}\n3 Losses {'ner': 15733.070828437805}\n4 Losses {'ner': 14729.110100502527}\n5 Losses {'ner': 14185.262874782085}\n6 Losses {'ner': 13574.499960422516}\n7 Losses {'ner': 13096.708367347717}\n8 Losses {'ner': 12478.775512218475}\n9 Losses {'ner': 12319.517817020416}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "negative_tweet_tr = []\nfor i in negative_tweet_train:\n    if i[0] != '':\n        negative_tweet_tr.append(i)",
      "execution_count": 28,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Test model"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "test_dataset = pd.read_csv(\"test.csv\")",
      "execution_count": 120,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "test_dataset[\"text\"] = test_dataset[\"text\"].apply(lambda x: x.strip())\ntest_dataset['n_text_words'] = test_dataset['text'].apply(lambda text: len(str(text).split()))",
      "execution_count": 68,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "pre_list = []\nfor i in range(test_dataset.shape[0]):\n    t_data = test_dataset.iloc[i]\n    if t_data.sentiment == 'neutral' or t_data.n_text_words <= 3:\n        pre_list.append(t_data.text)\n    elif t_data.sentiment == 'positive':\n        pre_list.append(test_model(ner_model_positive, t_data.text))\n    else:\n        pre_list.append(test_model(ner_model_negative, t_data.text))",
      "execution_count": 108,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create submission file"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "submission = pd.read_csv(\"./sample_submission.csv\")",
      "execution_count": 109,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "submission['selected_text'] = pre_list",
      "execution_count": 111,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "submission.head(10)",
      "execution_count": 112,
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>selected_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>f87dea47db</td>\n      <td>last session of the day</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>96d74cb729</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>eee518ae67</td>\n      <td>recession</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01082688c6</td>\n      <td>happy bday</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>33987a8ee5</td>\n      <td>i like it</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>726e501993</td>\n      <td>thats great</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>261932614e</td>\n      <td>hates</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>afa11da83f</td>\n      <td>blocked</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>e64208b4ef</td>\n      <td>and within a short time of the last clue all o...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>37bcad24ca</td>\n      <td>what did you get  my day is alright havent don...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "       textID                                      selected_text\n0  f87dea47db                            last session of the day\n1  96d74cb729                                               good\n2  eee518ae67                                          recession\n3  01082688c6                                         happy bday\n4  33987a8ee5                                          i like it\n5  726e501993                                        thats great\n6  261932614e                                              hates\n7  afa11da83f                                            blocked\n8  e64208b4ef  and within a short time of the last clue all o...\n9  37bcad24ca  what did you get  my day is alright havent don..."
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        },
        "trusted": false
      },
      "cell_type": "code",
      "source": "submission.to_csv(\"./submision_final.csv\")",
      "execution_count": 113,
      "outputs": []
    }
  ],
  "metadata": {
    "instance_type": "ml.t3.medium",
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}